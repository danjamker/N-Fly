<text id="J14" category="" words="2034" checkedby="" modifiedby="" Title="Cause and Cancer Epidemiology" Author="STEVEN N. GOODMAN & JONATHAN M. SAMET " PublicationDate="2006 In Cancer : epidemiology and prevention. Cancer Epidemiology and Prevention. Schottenfeld, David & Fraumeni Jr., Joseph F. (eds)" SampledFrom="New York ; Oxford : Oxford University Press, 2006" WebAddress="http://www.oxfordscholarship.com/oso/public/content/publichealthepidemiology/9780195149616/toc.html">

The prevention of disease has long been based implicitly on taking action on the assumption that a disease is caused by a factor that can be controlled. Early examples include the experimental evidence generated by Lind, showing that consumption of oranges and lemons prevented scurvy, and Snow's observations on cholera occurrence in London, showing a disease pattern consistent with water-borne transmission (Rosen, 1993). In these examples, preventive steps followed: After Lind's experiment, the diets of the British navy were supplemented with citrus fruits; and after Snow's observational study, steps were taken to ensure that the source of water was changed in the affected areas of London. Over the ensuing centuries, infectious agents were causally linked to specific diseases, and prevention was accomplished by interrupting transmission and by vaccines. During the twentieth century, public health was threatened by parallel epidemics of chronic diseases, including cancer; and as the causal agents were identified, a broad range of preventive strategies were implemented.
The concept of causation has long had a central role in the application of epidemiologic evidence for controlling cancer. The designation of a risk factor as "causal" has been the starting point for initiating cancer prevention programs based on reducing exposure to the risk factor. Although the concept of causation itself remains a matter of continuing discussion among philosophers and others, use of the term in public health implies that the evidence supporting causality of association has reached a critical threshold of certainty and that reduced exposure can be expected to be followed by reduced disease occurrence. Over the last 50 years, identification of the causes of cancer has been the primary focus of most epidemiologic research on cancer; only recently has attention shifted toward identifying genetic determinants of susceptibility and markers of the early stages of carcinogenesis.
There are numerous examples of how identifying a cause of cancer has led to intervention and reduction of cancer occurrence. Tobacco use and cancer of the lung is a notable example for its historical precedence and for the framework applied to the scientific evidence as the causality of the association was evaluated (US Department of Health Education and Welfare - DHEW, 1964; White, 1990). The range of causal risk factors for cancer is broad, including infectious agents (e.g., human papillomavirus and cervical cancer), physical agents (e.g., ionizing radiation and leukemia), inhaled agents (e.g., radon and lung cancer), pharmaceutical agents and hormones (e.g., diethylstilbestrol and adenocarcinoma of the vagina), food contaminants (e.g., aflatoxin and liver cancer), workplace exposures (e.g., asbestos), life style-related exposures (e.g., alcohol consumption), and genetic mutations (e.g., Li-Fraumeni syndrome). These and other factors considered to be causes of cancer have been given this label only after the accumulation of sufficient evidence, in most instances derived from both epidemiologic and laboratory research.
This chapter provides an overview of causal inference with a focus on the interpretation of epidemiologic data on cancer risk. It begins with an introduction to the centuries-old discussion on cause and causation and next considers the epidemiologic concept of causation, setting the discussion in the context of current understanding of carcinogenesis as a multistep process. The criteria for causation, often attributed to the British medical statistician Sir Austin Bradford Hill (Hill, 1965) or to the 1964 Report of the U.S. Surgeon General on tobacco (US Department of Health Education and Welfare - DHEW, 1964), have provided a framework for evaluating evidence to judge the causality of associations.
These criteria are addressed in depth, and their application is illustrated with the example of smoking, both active and passive, and lung cancer. The chapter concludes with a consideration of emerging issues concerned with causation, including the interpretation of data coming from the new technologies of contemporary "molecular epidemiology" and new approaches to evaluating causation.
CONCEPTS OF CAUSATION.
At its foundation, "cause" is not knowable with certainty. This fact underlies much of the methodologic and conceptual confusion that often swirls around claims of causation based on scientific data. The fundamental intuition underlying the causal concept is that event "A" somehow produces another event, "B." However, the "production" of "B" is not observable. The philosopher Bryan Magee summarized this conundrum eloquently.
It seems to be impossible for us to form any conception of an ordered world at all without the idea of there being causal connections between events. But when we pursue this idea seriously we find that causal connection is not anything we ever actually observe, nor ever can observe. We may say that Event A causes Event B, but when we examine the situation we find that what we actually observed is Event A followed by Event B. There is not some third entity between them, a casual link, which we also observe.... So we have this indispensable notion of cause at the very heart of our conception of the world, and of our understanding of our own experience, which we find ourselves quite unable to validate by observation or experience ... It actually purports to tell us how specific material events are related to each other in the real world, yet it is not derived from, nor can it be validated by, observation of that world. This is deeply mysterious. (Magee, 2001)
The fact that causation is not directly observable means that scientists and philosophers have had to develop a set of constructs and heuristics by which to define a "cause" operationally. These constructs typically have two components: a predictive or associational one, determined empirically, and an explanatory one, based on a proposed underlying mechanism. All causal claims rest on these twin pillars; an association with no plausible mechanistic basis is typically not accepted as causal, and a proposed mechanism, however well founded, cannot be accepted as the basis for a causal claim without empirical demonstration that the effect occurs more often in the presence of the purported cause than in its absence. However, these components need not contribute equally, and various causal claims may rest on quite different balances of contributions of empirical and mechanistic information.
Underlying any operational definition of causality must be an onto-logic one: that is, how a cause is defined in principle. A particularly useful, widely accepted definition in both philosophy and epidemiology is the "counterfactual" notion of causation. This concept had its origins at least as far back as the English philosopher David Hume (1711 - 1776) (Hume, 1739). During the twentieth century, this concept was further developed and applied by statisticians, philosophers, and epidemiologists.
The counterfactual definition holds that something is a cause of a given outcome if, when the same individual is observed with and without a purported cause and without changing any other characteristic of that individual, a different outcome would be observed. For example, the counterfactual state for a smoker is the same individual never having smoked. The state that cannot be observed is called the counterfactual state: literally, counter to the observed facts. The impossibility of observing the counterfactual state is what makes all causal claims subject to uncertainty.
The above definition is deterministic; that is, the outcome always occurs in the presence of the cause and never occurs without it. However, health research rarely deals with either a cause that inevitably produces certain outcomes, or outcomes that cannot occur absent specific causes. For example, smokers do not always get lung cancer, and never-smokers do develop this malignancy. Therefore, the counterfactual definition must be expanded to encompass the notion of a probabilistic outcome. That is, the formal definition of a cause in epidemiology requires that a factor X be associated with a difference in the probability of an outcome. 
For example, if X may take on two different values, y or z: 
Condition 1: observed association Pr(outcome | X = y) รฐ Pr(outcome | X = z)
Properly designed studies provide a scientific basis for inferring what the outcome of the counterfactual state would be and permit the related uncertainty to be quantified. In a laboratory, scientists are able to predict the outcome in this counterfactual state, generally with a high degree of confidence, by repeating an experimental procedure with every factor tightly controlled, varying only the factor of interest. In observational studies of humans, however, researchers must try to infer what the outcome would be in a counterfactual state by studying another group of persons who, at least on average, are substantively different from the exposed group in only one variable: the exposure under study. The outcome of this second group is used to represent what would have occurred in the original group if it were observed with an exposure different from that which actually existed (Greenland, 1990). In the case of smoking and disease, this comparison is between disease risk in smokers and nonsmokers.
Simply observing a difference in the probability of an outcome between two groups that differ on X is not sufficient condition for causation because it does not distinguish between causation and spurious or indirect association, produced by "confounders," or ancillary causes. The notion of "causation" requires that the cause somehow actively "produce" its effect, which is captured operationally by the requirement that active manipulation of the cause should produce a change in the probability of the outcome. For example, if one saw that students with poor visual acuity typically sat closer to the front of a classroom, one would not call the seating arrangement a "cause" of their poor eyesight unless it could be shown that seating them farther back improved it. The notation that captures this idea is one that introduces an operator, not part of traditional statistical notation "Set (X = x)," which corresponds to actively setting a risk factor X equal to some value x, rather than simply observing that the factor is equal to x. Thus the counterfactual notion of probabilistic causation for a risk factor X requires condition 2.
Condition 2: no confounding Pr(outcome | set[X = x)] = Pr(outcome | X = x)
If we put together condition 1 - that there is an observed association between cause and effect - with condition 2 - that there is no other indirect cause responsible for the observed effect - we have the counterfactual condition for probabilistic causation, expressed as follows.
Condition 1 + Condition 2 = Causality condition Pr[outcome | set(X = y)] รฐ Pr[outcome | set(X = z)]
This condition states that if the probability of an outcome changes when risk factor X is actively changed from z to y, then X is regarded as a cause of the outcome.
In the randomized controlled trial, a risk factor is actively manipulated. Understanding the role of randomization can deepen insights into the interpretation of nonrandomized designs used in epidemiology. Randomization has two critical consequences: (1) it makes exposure to a proposed causal factor independent of potentially confounding factors; and (2) it provides a known probability distribution for the potential outcomes in each group under a given mathematical hypothesis (i.e., the null) (Greenland, 1990). Randomization does not necessarily free the inference from an individual randomized study from unmeasured confounding (it does so only on average). Randomization does imply that measures of uncertainty about causal estimates from randomized studies have an experimental foundation. In the absence of randomization, uncertainty about causal effects depends in part on the confidence that all substantive confounding has been eliminated or controlled by either the study design or the analysis. The level of confidence is ultimately based on scientific judgment and consequently is subject to uncertainty and questioning.
One way to increase that confidence is to repeat the study. Similar results in a series of randomized studies make it increasingly unlikely that unmeasured confounding is accounting for the findings, as the process of randomization makes the mathematical probability of such confounding progressively smaller as the sample size or number of studies increase. In observational studies, however, increasing the number of studies may reduce the random component of uncertainty, but not necessarily the systematic component attributable to confounding. Without randomization, there is no mathematical basis for assuming that an imbalance of unknown confounders decreases with an increase in the number of studies. However, if observational studies are repeated in different settings with different persons, different eligibility criteria, and/or different exposure opportunities, each of which might eliminate another source of confounding from consideration, the confidence that unmeasured confounders are not producing the findings is increased.

</text>
