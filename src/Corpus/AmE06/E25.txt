<text id="E25" category="" words="1998" checkedby="" modifiedby="" Title="'Don't Even Think About Lying: How brain scans are reinventing the science of lie detection.' Wired Magazine, Issue 14.01 - January 2006" Author="Steve Silberman" PublicationDate="January 2006" SampledFrom="End" WebAddress="http://www.wired.com/wired/archive/14.01/lying.html?pg=1&topic=lying&topic_set=">

Laken and Kozel recently launched another DoDPI-funded study designed to mimic as closely as possible the emotions experienced while committing a crime. In the spring, after this research is complete, Laken will start looking for Cephos' first clients - ideally "people who are trying to show that they're being truthful and who want to use our technology to help support their cases."
No Lie MRI will debut its services this July in Philadelphia, where it will demonstrate the technology to be used in a planned network of facilities the company is calling VeraCenters. Each facility will house a scanner connected to a central computer in California. As the client responds to questions using a handheld device, the imaging data will be fed to the computer, which will classify each answer as truthful or deceptive using software developed by Langleben's team. For No Lie MRI founder Joel Huizenga, scanner-based lie detection represents a significant upgrade in "the arms race between truth-tellers and deceivers."
Both Laken and Huizenga play up the potential power of their technologies to exonerate the innocent and downplay the potential for aiding prosecution of the guilty. "What this is really all about is individuals who come forward willingly and pay their own money to declare that they're telling the truth," Huizenga says. (Neither company has set a price yet.) Still, No Lie MRI plans to market its services to law enforcement and immigration agencies, the military, counterintelligence groups, foreign governments, and even big companies that want to give prospective CEOs the ultimate vetting. "We're really pushing the positive side of this," Huizenga says. "But this is a company - we're here to make money."
Scott Faro, a radiologist at Temple University Hospital who conducted experiments using fMRI in tandem with the polygraph, predicts that the invention of a more accurate lie detector "is going to change the entire judicial system. First it will be used for high-profile crimes like terrorism and Enron. You could have centers across the country built close to airports, staffed with cognitive neuroscientists, MRI physicists, and interrogation experts. Eventually you could have 20 centers in each major city, and the process will start to become more streamlined and cost-effective.
"People say fMRI is expensive," Faro continues, "but what's the cost of a six-month jury trial? And what's the cost to America for missing a terrorist? If this is a more accurate test, I don't see any moral issues at all. People who can afford it and believe they are telling the truth are going to love this test."
The guardians of another Philadelphia innovation that changed the judicial system - the US Constitution - are already sounding the alarm. In September, the Cornell Law Review weighed the legal implications of the use of brain imaging in courtrooms and federal detention centers, calling fMRI "one of the few technologies to which the now clichéd moniker of 'Orwellian' legitimately applies."
When lawyers representing Cephos' and No Lie MRI's clients come to court, the first legal obstacles they'll have to overcome are the precedents barring so-called junk science. Polygraph evidence was excluded from most US courtrooms by a 1923 circuit court decision that became known as the Frye test. The ruling set a high bar for the admission of new types of scientific evidence, requiring that a technology have "general acceptance" and "scientific recognition among physiological and psychological authorities" to be considered. When the polygraph first came before the courts, it had almost no paper trail of independent verification.
FMRI lie detection, however, has evolved in the open, with each new advance subjected to peer review. The Supreme Court has already demonstrated that it is inclined to look favorably on brain imaging: A landmark 2005 decision outlawing the execution of those who commit capital crimes as juveniles was influenced by fMRI studies showing that adolescent brains are wired differently than those of adults. The acceptance of DNA profiling may be another bellwether. Highly controversial when introduced in the 1980s, it had the support of the scientific community and is now widely accepted in the courts.
The introduction of fMRI evidence at trial may have to be vetted against legal precedents designed to prevent what's called invading the province of the jury, says Carter Snead, former general counsel for the President's Council on Bioethics. In 1973, a federal appeals court ruled that "the jury is the lie detector" and that scientific evidence and expert testimony can be introduced only to help the jury reach a more informed judgment, not to be the final arbiter of truth. "The criminal justice system is not designed simply to ensure accurate truth finding," Snead says. "The human dimension of being subjected to the assessment of your peers has profound social and civic significance. If you supplant that with a biological metric, you're losing something extraordinarily important, even if you gain an incremental value in accuracy."
No Lie MRI's plans to market its services to corporations will likely run afoul of the 1988 Employee Polygraph Protection Act, which bars the use of lie-detection tests by most private companies for personnel screening. Government employers, however, are exempt from this law, which leaves a huge potential market for fMRI in local, state, and federal agencies, as well as in the military.
It is in these sectors that fMRI and other new lie-detection technologies are likely to take root, as the polygraph did. The legality of fMRI use by government agencies will probably focus on issues of consent, predicts Jim Dempsey, executive director of the Center for Democracy &amp; Technology, a Washington, DC-based think tank. "From a constitutional standpoint, consent covers a lot of sins," he explains. "Most applications of the polygraph in the US have been in consensual circumstances, even if the consent is prompted by a statement like 'If you want this job, you must submit to a polygraph.' The police can say, 'Would you blow into this Breathalyzer? Technically you're free to say no, but if you don't consent, we're going to make life hard for you.'"

Today's fMRI scanners are bulky, cost up to $3 million each, and in effect require consent because of their sensitivity to head movement. Once Cephos and No Lie MRI make their technology commercially available, however, these limitations will seem like glitches that merely need to be fixed. If advances make it possible to perform brain scans on unwilling or even unwitting subjects, it will raise a thicket of legal issues regarding privacy, constitutional protections against self-incrimination, and the prohibitions against unlawful search and seizure.

The technological innovations that produce sweeping changes often evolve beyond their designers' original intentions - the Internet, the cloud chamber, a 19th-century doctor's cuff for measuring blood pressure that, when incorporated into the polygraph, became the unsteady foundation of the modern counterintelligence industry.
So what began as a neurological inquiry into why kids with ADHD blurt out embarrassing truths may end up forcing the legal system to define more clearly the inviolable boundaries of the self.
"My concern is precisely with the civil and commercial uses of fMRI lie detection," says ethicist Paul Root Wolpe. "When this technology is available on the market, it will be in places like Guantánamo Bay and Abu Ghraib in a heartbeat.
"Once people begin to think that police can look right into their brains and tell whether they're lying," he adds, "it's going to be 1984 in their minds, and there could be a significant backlash. The goal of detecting deception requires far more public scrutiny than it has had up until now. As a society, we need to have a very serious conversation about this."


Your flight is now boarding. Please walk through the "mental detector."
For all the promise of fMRI lie detection, some practical obstacles stand in the way of its widespread use: The scanners are huge and therefore not portable, and a slight shake of the head - let alone outright refusal to be scanned - can disrupt the procedure. Britton Chance, a professor emeritus of biophysics at the University of Pennsylvania, has developed an instrument that records much of the same brain activity as fMRI lie detection - but fits in a briefcase and can be deployed on an unwilling subject.
Chance has spent his life chasing and quantifying elusive signals - electromagnetic, optical, chemical, and biological. During the Second World War, he led the team at the MIT Radiation Lab that helped develop military radar and incorporated analog computers into the ranging system of bombers. In the 1970s, long before the invention of fMRI, Chance began using a related technique called magnetic-resonance spectroscopy to study living tissue. The first functionally imaged brain was that of a hedgehog in one of his experiments. Now 92, Chance still rides his bike to the university six days a week to teach and work in his lab. His mind is as acute as ever. After glancing through a book to confirm a data point, he resumes the conversation by saying, "I'm back online."
He explains that his goal is to create a wearable device "that lets me know what you're thinking without you telling me. If I ask you a question, I'd like to know before you answer whether you're going to be truthful."
To map neural activity without fMRI, Chance uses beams of near-infrared light that pass harmlessly through the forehead and skull, penetrating the first few centimeters of cortical tissue. There the light bounces off the same changes in blood flow tracked by fMRI. When it reemerges from the cranium, this light can be captured by optical sensors, filtered for the "noise" of light in the room, and used to generate scans.
Though near-infrared light doesn't penetrate the brain as deeply as magnetic resonance, some of the key signatures of deception mapped by fMRI researchers occur in the prefrontal cortex, just behind the forehead. The first iteration of Chance's lie detector consisted of a Velcro headband studded with LEDs and silicon diode sensors. Strapping these headbands on 21 subjects in a card-bluffing experiment in 2004, a neuroscientist at Drexel named Scott Bunce was able to accurately detect lying 95 percent of the time. The next step, Chance says, is to develop a system that can be used discreetly in airports and security checkpoints for "remote sensing" of brain activity. This technology could be deployed to check for deception during standard question-and-answer exchanges (for example, "Has anyone else handled your luggage?") with passengers before boarding a plane, or during interviews with those who have been singled out for individual searches.
With funding from the Office of Naval Research, Chance and his colleagues are working to replace the LED headband with an invisible laser and a hypersensitive photon collector to create a system that can pick up the neural signals of deception from across a room.
Before undertaking this project, Chance consulted with Arthur Caplan, director of Penn's Center for Bioethics. "Dr. Chance was a little uneasy about it," Caplan recalls. "But there are certain public places where we lose the right to privacy as a condition of entering the building. Airport security staff is allowed to search your bag, your possessions, and even your body. In my view, there's no blanket rule that says it's always wrong to scan someone without their consent. What we need is a set of policies to determine when you have to have consent."
Chance believes the virtues of what he calls "a network to detect malevolence" outweigh the impact on personal liberties. "It would certainly represent an invasion of privacy," he says. "I'm sure there may be people who, for very good reasons, would not want to come near this device - and they're the interesting ones. But we'll all feel a bit safer if this kind of technology is used in places like airports. If you don't want to take the test, you can turn around and fly another day." Then he smiles. "Of course, that's the biggest selector of guilt you could want."

</text>
