where q is the measured current flux on the outer boundary. The domain D can be parameterised in different forms, and the parameters characterising the shape, location and size of the cavity are determined by minimising the functional (9). In this paper, we only investigate the cases of circular cavities, but similar solution methods may be developed for any shape for which the uniqueness of the solution is guaranteed. 
Once the problem has been reformulated as an optimisation problem, the objective functional (9) can be minimised using various optimisation algorithms. However, it has been shown in Mera et al. [15] that gradient based algorithms are outperformed by evolutionary algorithms due to the multi-modal structure of the objective function. However, one disadvantage of evolutionary algorithms is the large number of objective function evaluations required to obtain convergence toward the global optimum. It is the purpose of this paper to show that a speed up in the optimisation process can be achieved by using neural network models to approximate the objective function (9). 
3. An evolution strategy
In order to solve the inclusion detection problem, the previous studies by Mera et al. [13] and [14] used a floating point number encoded genetic algorithm similar to the one proposed in Michalewicz [19]. However, in this study we use a (? + ?) evolution strategy since it has been reported to be more efficient in dealing with numerical optimisation problems, see Schwefel [22], due to the a more complex adaptation scheme involving both objective variables and control variables. The standard evolution strategy (? + ?) ES operates on a n-dimensional vector using the mutation operator as the main operator. The algorithm encodes and adapts the unknown variables xi and the mutation step size and direction. Every individual in the population of the ES has the form . The vector contains the object variables, i.e. the only part of an individual entering the objective function. The vector contains the mutation step-sizes, i.e. standard deviations of the Gaussian distribution used for simulating mutation and the vector contains inclination angles, defining correlated mutations of the object variable x. The latter two vectors are called strategy parameters and they determine the variances and covariances of the n-dimensional Gaussian mutation probability density that is used for exploring the space of the object variables . 
An initial population of ? individuals is randomly created and the objective function is evaluated for every individuals. At every generation a number of ? children are created as follows: 
(a) From a number of ? randomly selected parents a successor () is constructed using uniform recombination for the unknown variables xi and local intermediary recombination for the mutation step sizes ?i.
(b) A child is created as follows:

where the strategy parameters ? and ?? are usually fixed to be

? = 5° = 0.0873 radians and the covariance matrix is constructed using the variances and the covariances , see Schwefel (1981). The z, zi, zj and are normally distributed numbers and a random vector, respectively, which characterize the mutation exercised on the strategy and the objective parameters. 
Deterministic selection is employed to select the ? survivors out of the (? + ?) individuals available and the evolution is continued by generating a new set of ? children. 
The strategy parameters and are subject to self-adaptation according to Eqs. (10) and (12). Since they define the variances and covariances of the normal probability distribution that governs the mutation operator, see Eq. (13), they stochastically define the direction and the step size of the search process in the n-dimensional space. Thus, the (? + ?) ES performs adaptation not only on the search position but also on the search direction and size. The (? + ?) ES was found to outperform other evolutionary algorithms on the cavity identification problem investigated in this paper. Details of the (? + ?) ES can be found in Back [1]. 
In general, in practical optimisation problems, once a parameterisation has been employed and a suitable objective function has been developed, one is left with optimising this complex, computationally expensive, usually multi-dimensional multi-modal objective function. Various optimisation methods are available for optimising such objective function and their performance depends on the characteristics of the objective function. Gradient based methods such as the Sequential Quadratic Programming (SQP) may be used, see Hofmann et al. [5], Schulz [23], Hoppe et al. [6], Hoppe and Petrova [7] or Mera et al. [17]. However, the output of numerical computer codes that evaluate the objective function is usually affected by many approximation, rounding and truncation errors. These errors are not stochastic, they are reproducible, but their accumulation introduces high-frequency, low-amplitude distortions of the idealized objective function that should be optimised. Thus, in many optimisation problems the objective function has a rough surface with numerous plateaus and ridges. On these local plateaus, methods that use gradient calculations can get stuck since zero gradients are obtained. Also, there are many points where the objective function is not smooth and the gradients can not be efficiently calculated. In consequence, optimisation algorithms that compute or approximate by finite differencing the derivatives of the objective function, often fail to exploit general trends in the objective function. Moreover, often in inverse boundary detection problems the objective function has a multi-modal structure, see Mera et al. [17]. Deterministic, gradient-based optimisation methods do not search the parameter space and can tend to converge towards local extrema of the fitness function, which is clearly unsatisfactory for problems where the fitness varies non-monotonously with the parameters. Consequently, it is required to use an optimisation algorithm that can deal with a multi-modal structure without getting trapped in local optima, see Mera et al. [17] which compares a SQP method and an evolutionary algorithm for a three-dimensional boundary detection problem. By using a population of solutions rather than just one individual solution and by using probabilistic transition rules, not deterministic rules, to guide their search genetic algorithms are able to depart from local optima. Therefore, in this study we use for the optimisation process the evolution strategy described in this section. 
4. Fitness approximation in evolutionary computation
Evolutionary algorithms have proved to be robust and efficient optimisers that are well-suited for discontinuous and multi-modal objective functions. Various types of evolutionary algorithms have been successfully applied to complex real-world applications where the fitness function evaluation is not straight-forward. In some optimisation tasks, the functions to optimise are analytical expressions that take a negligible amount of time to compute. However, in the case of realistic engineering design problems, the optimisation function is a computationally expensive code which can take up to several hours of CPU time. One essential disadvantage of employing evolutionary algorithms in such applications is the huge time consumption due to the high complexity of the solvers for objective function evaluation. Consequently, it is desirable to use reduced models which are usually much faster than the actual objective function. Reduced models can be mathematical approximations, such as response surface induced using some evaluations of the original expensive model, see Jin and Sendhoff [9], or can be approximations based on a different level of discretisation, such as the injection island model, see Eby et al. [3]. Fitness approximation models in evolutionary computation have been found to be useful tools if the computation of the fitness is time consuming, as in structural design optimisation, if there is no explicit model for fitness computation, as in interactive evolutionary computation, if the environment of the evolutionary algorithm is noisy or if the fitness function is multi-modal and global approximation models can be constructed to smooth out the local optima of the original multi-modal function without changing the global optimum and its location, see Jin and Sendhoff [9]. There are two major concerns in using approximate models for objective function evaluation. First, it should be ensured that the evolutionary algorithm converges to the global optimum or a near optimum of the original objective function. Second, the computational cost of building and evaluating the reduced model should be reduced as much as possible. 
In an ideal situation it would be possible to sample a few points from the search space, evaluate these points with the original objective function, construct a reduced approximation model using these points and obtain the solution of the problem as the global optimum of the reduced model constructed. However, in most practical situations it is impossible to construct an approximate model that is globally correct due to the high-dimensionality of the problem, ill distribution and a limited number of training samples. Therefore, it is important to use both the original and the approximate objective functions during the optimisation process in an evolutionary algorithm. There are several possibilities to combine the original objective function and the approximate objective function. We consider in this paper two approaches, the informed operators technique and the controlled evolution technique which are described in the remainder of this section. 
4.1. Informed operators for evolutionary algorithms
In the informed operators techniques, see Rasheed et al. [21], the operators of the evolutionary algorithm extract useful information from the approximated objective function and this information is used in generating children in the promising regions of the search space. The approximated objective function is only used during the mutation and recombination operators as follows: 
• Informed mutation: To do mutation, several random mutations are generated of the base point. Each mutation is generated by randomly selecting the parameters for the original mutation method. The offsprings created are evaluated using the approximated objective function. The mutation that appears best according to the reduced model is returned as the result of the mutation operator.
• Informed recombination: To do recombination, the parents are selected at random according to the original selection strategy. These two parents will not change in the course of the informed recombination operation. Several recombinations are conducted by randomly selecting the internal parameters of the recombination operators. Each individual generated is evaluated with the reduced model and the best is considered to be the outcome of the recombination operator.
In this paper since we use a (? + ?) ES which relies mainly on the mutation operator, we avoid wasting evaluated candidates in the recombination operator. Therefore for every children we create k candidates by using both the recombination and mutation operators described in Section 3. Clearly, these individuals will be different since different random numbers z, zi and are generated for every candidate. These candidates are evaluated using the approximated objective function. The candidate which appears best according to the reduced model is considered to be a new born child and is evaluated with the original fitness function. Thus at any point during the evolution process, all the individuals which have survived have been evaluated by the original objective function. The number k of candidates generated for a child is an internal parameter of the IOGA and various values are investigated in this paper. 
This approach has the advantage that it does not require assumptions about the accuracy of the reduced model. Indeed, in the evolution process, the survival of the individuals is governed solely by the original objective function. The approximate objective function is only used to suggest promising regions in the search space. The only requirement is that the reduced model is a better than a random approximation. 
The approximation model is updated every generation or every few generations. In this paper, the approximation model is trained every generation on the actual population of the evolution strategy. This results in the creation of local models which are highly accurate in the region where the evolutionary search has focused, although they are less accurate in other regions of the search space. Such a training strategy is very efficient in the later stages of the evolution, once the whole population has converged to a region in the search space. 
4.2. Controlled evolution in evolutionary algorithms

